{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZtx0eDC5kHy"
      },
      "source": [
        "---\n",
        "**In this project, we will build a sentiment analysis using yelp and distillBERT**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBCvM9LH_QQv"
      },
      "source": [
        "# **Imports and IDE Configs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OQiXXUmRZcM"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9RV72krxfzw"
      },
      "source": [
        "download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gg0ut1b9uEwt"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle/\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75ryS_v7rjyS"
      },
      "outputs": [],
      "source": [
        "# downnlaod yelp dataset\n",
        "!kaggle datasets download -d yelp-dataset/yelp-dataset\n",
        "!unzip yelp-dataset.zip\n",
        "# delete everything except review file\n",
        "!find . -type f -not -name 'yelp_academic_dataset_review.json' -delete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ-DxV4exhrZ"
      },
      "source": [
        "import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQvr0QyF_Xc9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments, DistilBertModel\n",
        "from datasets import Dataset #hugginface datasets\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdkStWs5_JmT"
      },
      "source": [
        "# **Load dataset and EDA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRr09Nfb_Ym_"
      },
      "outputs": [],
      "source": [
        "chunk_size = 20000  # adjust based on available memory\n",
        "dataset_path = \"yelp_academic_dataset_review.json\"\n",
        "json_reader = pd.read_json(dataset_path, lines=True, chunksize=chunk_size) # this get all the chunks of json file (as the file is too large, cannot load all at once)\n",
        "df = next(json_reader) # loading first chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKrmchxEVXXy"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMA2oAfW3bxp"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmfBZwxls4OK"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KrfmiwzMWMc"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjDkiLzNKQQc"
      },
      "outputs": [],
      "source": [
        "# Assuming your DataFrame is named df and has a 'stars' column\n",
        "df['stars'].value_counts().sort_index().plot(kind='bar', title='Star Ratings Distribution')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWDiPLc08ArU"
      },
      "outputs": [],
      "source": [
        "temp_text = ''.join(df.text)\n",
        "# Generate word cloud\n",
        "wordcloud = WordCloud(width = 800, height = 800,\n",
        "                      background_color ='white',\n",
        "                      min_font_size = 10).generate(temp_text)\n",
        "\n",
        "# Plotting the WordCloud\n",
        "plt.figure(figsize = (8, 8), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kJFU4PIL6Zi"
      },
      "source": [
        "# **Data Processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE3KC3LoWywp"
      },
      "source": [
        "Data Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYpwRU8OPwMD"
      },
      "outputs": [],
      "source": [
        "# Text cleaning function (customize as needed)\n",
        "def clean_text(text):\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www.\\S+', '[URL]', text)\n",
        "    # Remove Emails\n",
        "    text = re.sub(r'\\S+@\\S+', '[EMAIL]', text)\n",
        "    # Remove new line and line breaks\n",
        "    text = text.replace('\\n', ' ').replace('\\r', '').strip()\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    # Optional: Lowercase (Depends on whether your DistilBERT model is cased or not)\n",
        "    # text = text.lower()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta-z-Y-bEs2Y"
      },
      "outputs": [],
      "source": [
        "# filtering\n",
        "df.drop(columns=['review_id','user_id','business_id'],inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "# Clean the 'text' column\n",
        "df['clean_text'] = df['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYsXAY2-W32I"
      },
      "source": [
        "Data Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYv4yytuW8IR"
      },
      "outputs": [],
      "source": [
        "# Ordinal encoding\n",
        "# as ordinal encoding is expected to be 0-n but stars were 1-5. so reducing by 1.\n",
        "df['stars'] = df['stars'] - 1 # feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_XIRqtOXXgJ"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xh-V8Ke8bUjN"
      },
      "outputs": [],
      "source": [
        "# validation splitting\n",
        "train_df, val_df = train_test_split(df, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRj82OTdE39P"
      },
      "outputs": [],
      "source": [
        "# model needs int64 data and this stars originally were float.\n",
        "train_df['stars'] = train_df['stars'].astype(int)\n",
        "val_df['stars'] = val_df['stars'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKCHfHGFa3N7"
      },
      "outputs": [],
      "source": [
        "# preparing huggingface datsets with expected column names (for the tokenizer and model)\n",
        "train_data = Dataset.from_pandas(train_df[['text', 'stars']].rename(columns={'text': 'text', 'stars': 'label'}))\n",
        "val_data = Dataset.from_pandas(val_df[['text', 'stars']].rename(columns={'text': 'text', 'stars': 'label'}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgD-cQg0sOEG"
      },
      "source": [
        "# **Model Loading and Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yer8GnR4cnXU"
      },
      "outputs": [],
      "source": [
        "# Initialize the tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding='max_length', truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0oBz6nHbw4Q"
      },
      "outputs": [],
      "source": [
        "# tokenize dataset\n",
        "train_data_tokenized = train_data.map(tokenize_function, batched=True)\n",
        "val_data_tokenized = val_data.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z44sMH1ryE3S"
      },
      "outputs": [],
      "source": [
        "# hugging face's this model is in torch, so we need to convert the type to torch dataset.\n",
        "# Format for pytorch\n",
        "train_data_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "val_data_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id1zdvun4GEw"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    fp16=True,  # Enable mixed precision training\n",
        "    gradient_accumulation_steps=2,  # Example value\n",
        "    logging_steps=100  # Reduced logging frequency\n",
        ")\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=len(train_data_tokenized['label'].unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCoTDs6w9-J8"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer( #hugggingface trainer module takes care of parallel trainig.\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data_tokenized,\n",
        "    eval_dataset=val_data_tokenized\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbG2DjWeK_1y"
      },
      "outputs": [],
      "source": [
        "num_labels = len(train_data_tokenized['label'].unique())\n",
        "model_config_num_labels = model.config.num_labels\n",
        "\n",
        "print(f\"Dataset num_labels: {num_labels}\")\n",
        "print(f\"Model config num_labels: {model_config_num_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SPlBERNVJOV"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QvebzpoD0ZR"
      },
      "outputs": [],
      "source": [
        "#save to s3\n",
        "model.save_pretrained(\"./models/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqOxco91j6VL"
      },
      "source": [
        "# **inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jb6JXCGD4NZR"
      },
      "outputs": [],
      "source": [
        "# text = \"Replace me by any text you'd like.\"\n",
        "# encoded_input = tokenizer(text, return_tensors='pt')\n",
        "# output = model(**encoded_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8cYYYg-P8mu"
      },
      "outputs": [],
      "source": [
        "test_text = [\"food is awesome!\",\"It was best\",\"I hate it\"]\n",
        "test_encodings = tokenizer(test_text, padding=True, truncation=True, return_tensors='pt')\n",
        "test_dataset = Dataset.from_dict(test_encodings)\n",
        "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
        "\n",
        "predictions = trainer.predict(test_dataset)\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "logits = torch.tensor(predictions.predictions)\n",
        "probabilities = F.softmax(logits, dim=0)\n",
        "print(probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tlt1S7tNgspM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chs0-22Eh3ml"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjvYgoAIg16O"
      },
      "outputs": [],
      "source": [
        "print(predictions.predictions[0]),predictions.predictions[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wALIt2AhaBi"
      },
      "outputs": [],
      "source": [
        "predictions.predictions[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZTqJbZPgydW"
      },
      "outputs": [],
      "source": [
        "predicted_label_idx = torch.argmax(predictions.predictions[0]).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSgU_ZeSgzI4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
